# üöÄ Hands-On: Python, PyTorch & TensorFlow Foundation

This project serves as a comprehensive quick-start guide to deep learning frameworks. It is designed to help developers (especially those transitioning from languages like Java) master core operations and understand the syntactic differences between **PyTorch** and **TensorFlow**.

## üìå Project Highlights

* **Fundamental Concepts**: Covers everything from advanced Python syntax (List Comprehension, Classes) to core data processing with NumPy.
* **Dual-Framework Comparison**: Implements the same computational logic side-by-side in both PyTorch and TensorFlow.
* **Tensor Manipulation**: Practical exercises on tensor creation, reshaping, dimensional operations, and arithmetic.
* **Automatic Differentiation (Autograd)**: A clear demonstration of gradient computation‚Äîthe backbone of deep learning.

---

## üìñ Table of Contents

### 1. Python & NumPy Reinforcement

Essential data handling tools before diving into deep learning:

* **Python Basics**: List comprehensions, dictionary operations, and function definitions.
* **Object-Oriented Programming (OOP)**: Understanding classes and inheritance‚Äîfundamental for building neural network architectures like `nn.Module`.
* **NumPy Arrays**: Matrix operations, broadcasting mechanisms, and indexing techniques.

### 2. PyTorch Core Implementation

Exploration of PyTorch‚Äôs famous Dynamic Computational Graph:

* **Tensor Operations**: Creation, reshaping, and transposing.
* **CUDA Support**: Methods to check for and move operations to the GPU for performance acceleration.
* **Gradient Computation**: Using `.backward()` for automatic differentiation.

### 3. TensorFlow Core Implementation

Understanding the industry-standard deep learning engine by Google:

* **Eager Execution**: Exploring the immediate execution features of TF 2.x.
* **Tensor Manipulation**: Syntax comparison with NumPy and PyTorch.
* **Comparative Analysis**: Identifying subtle differences in constant handling and computational logic between frameworks.

---

## üõ†Ô∏è Installation & Setup

It is recommended to run this notebook in Google Colab or a local Anaconda environment:

```bash
# Install core dependencies
pip install torch torchvision
pip install tensorflow
pip install numpy matplotlib

```

## üìä Framework Comparison at a Glance

| Feature | PyTorch | TensorFlow |
| --- | --- | --- |
| **Computational Graph** | Dynamic | Static / Dynamic (Eager by default) |
| **API Design** | Intuitive, Pythonic | Hierarchical (Keras integration) |
| **Debugging** | Easier (Standard Python tools) | Improved in 2.x via Eager execution |
| **Primary Use Case** | Academic Research, Rapid Prototyping | Industrial Deployment, Production |

## üèÅ Learning Outcomes
Through this module, I have successfully achieved:

1. **Syntax Transition**: Seamlessly converting data between NumPy arrays, PyTorch Tensors, and TensorFlow Tensors.
2. **Hardware Scheduling**: Mastered moving tensors to the GPU (CUDA) for large-scale parallel computing.
3. **Logical Construction**: Gained a deep understanding of how neural networks perform weight updates through tensor multiplication and backpropagation.
